# Running Jupyter notebook as tests.

# TODO(jlewi): We need to reorganize the files and put this into templates/tasks and create a suitable
# kustomize directory in installs to install it the appropriate namespace on the test cluster
apiVersion: tekton.dev/v1alpha1
kind: Task
metadata:
  name: nb-tests
  namespace: tektoncd
  annotations:
    sidecar.istio.io/inject: "false"
spec:
  inputs:
    params:
    - name: notebook-path
      type: string
      description:
        Testing notebook location. Should be in the form of
        {REPO_OWNER}/{REPO}/path/to/notebook.ipynb
    - name: testing-cluster-pattern
      type: string
      description:
        Cluster pattern to run the notebook test.
        Default to be from master branch.
    - name: artifacts-gcs
      type: string
      description:
        GCS bucket and directory artifacts will be uploaded to.
        Should be in the form of 'gs://'
    - name: junit-path
      type: string
      description:
        Relative path to the GCS artifacts will be uploaded to.
        Base path is artifacts-gcs so the actual GCS blob will be
        artifacts-gcs/junit-path
    - name: test-target-name
      type: string
      description:
        Test targe name, used to group test results in JUNIT.
      default: manual-testing
    - name: output-workspace
      type: string
      description:
        Directory to write outputs to in local FS.
    # TODO(jlewi): Lets not use targetPath. Instead lets rely on Tekton checking repos
    # out to /workspace/$(resource.name)
    resources:
    - name: examples-repo
      type: git
      targetPath: src/kubeflow/examples
    - name: kf-testing-repo
      type: git
      targetPath: src/kubeflow/testing
  steps:
  - name: get-credential
    image: gcr.io/kubeflow-ci/test-worker:latest
    command:
    - python3
    args:
    - -m
    - kubeflow.testing.get_kf_testing_cluster
    - --base=$(inputs.params.testing-cluster-pattern)
    - get-credentials
    env:
    - name: PYTHONPATH
      value: /workspace/src/kubeflow/examples/py:/workspace/src/kubeflow/testing/py
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: /secret/gcp-credentials/key.json
    volumeMounts:
    - name: gcp-credentials
      readOnly: true
      mountPath: /secret/gcp-credentials
  - name: run-notebook
    image: gcr.io/kubeflow-ci/test-worker:latest
    # Need to use script as workaround not to error out in tests.
    # If any of the steps returns non-zero codes, subsequent steps will not be run.
    script: |
        #!/usr/bin/env bash
        pytest run_notebook_test.py \
          --log-cli-level=info \
          --log-cli-format='%(levelname)s|%(asctime)s|%(pathname)s|%(lineno)d| %(message)s' \
          --timeout=1800 \
          --junitxml=$(inputs.params.junit-path) \
          --notebook_path=$(inputs.params.notebook-path) \
          --test-target-name=$(inputs.params.test-target-name) \
          --artifacts-gcs=$(inputs.params.artifacts-gcs) \
        || echo test finished.
    workingDir: /workspace/src/kubeflow/examples/py/kubeflow/examples/notebook_tests
    env:
    - name: PYTHONPATH
      value: /workspace/src/kubeflow/examples/py:/workspace/src/kubeflow/testing/py
    # TODO(jlewi): Can we use Workload Identity?
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: /secret/gcp-credentials/key.json
    volumeMounts:
    - name: gcp-credentials
      readOnly: true
      mountPath: /secret/gcp-credentials
  # This step is designed to be generic: given the output directory, it will try to
  # parse all the XML files with prefix of junit and error out if failures been found.
  - name: copy-artifacts
    image: gcr.io/kubeflow-ci/test-worker:latest
    command:
    - python
    args:
    - -m
    - kubeflow.testing.tekton_client
    - junit_parse_and_upload
    - --artifacts_dir=$(inputs.params.output-workspace)
    - --output_gcs=$(inputs.params.artifacts-gcs)
    env:
    - name: PYTHONPATH
      value: /workspace/src/kubeflow/examples/py:/workspace/src/kubeflow/testing/py
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: /secret/gcp-credentials/key.json
    volumeMounts:
    - name: gcp-credentials
      readOnly: true
      mountPath: /secret/gcp-credentials
  volumes:
  - name: gcp-credentials
    secret:
      secretName: gcp-credentials
